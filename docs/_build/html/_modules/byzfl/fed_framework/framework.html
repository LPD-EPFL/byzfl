
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>byzfl.fed_framework.framework &#8212; ByzFL</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=b8db6181" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/byzfl/fed_framework/framework';</script>
    <script src="../../../_static/custom-icon.js?v=74687d30"></script>
    <link rel="icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/byzfl_logo.png" class="logo__image only-light" alt="ByzFL - Home"/>
    <img src="../../../_static/byzfl_logo.png" class="logo__image only-dark pst-js-only" alt="ByzFL - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../aggregators/index.html">
    Aggregators
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../attacks/index.html">
    Attacks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../fed_framework/index.html">
    Federated Learning Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../team/index.html">
    Our Team
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/LPD-EPFL/byzfl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/byzfl/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../aggregators/index.html">
    Aggregators
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../attacks/index.html">
    Attacks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../fed_framework/index.html">
    Federated Learning Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../team/index.html">
    Our Team
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/LPD-EPFL/byzfl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/byzfl/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">byzfl.fed_framework.framework</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for byzfl.fed_framework.framework</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">byzfl.aggregators</span> <span class="kn">import</span> <span class="n">aggregators</span>
<span class="kn">from</span> <span class="nn">byzfl.aggregators</span> <span class="kn">import</span> <span class="n">preaggregators</span>
<span class="kn">import</span> <span class="nn">byzfl.attacks</span> <span class="k">as</span> <span class="nn">attacks</span>
<span class="kn">import</span> <span class="nn">byzfl.fed_framework.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="kn">from</span> <span class="nn">byzfl.utils.conversion</span> <span class="kn">import</span> <span class="n">flatten_dict</span><span class="p">,</span> <span class="n">unflatten_dict</span><span class="p">,</span> <span class="n">unflatten_generator</span>
<span class="kn">from</span> <span class="nn">byzfl.utils.misc</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">collections</span>

<span class="k">class</span> <span class="nc">ModelBaseInterface</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>
<span class="sd">    The ``ModelBaseInterface`` class serves as an abstract interface that defines the methods </span>
<span class="sd">    required for classes that encapsulate a model. All subclasses that </span>
<span class="sd">    contain a model should inherit from this class to ensure they implement </span>
<span class="sd">    the necessary methods for handling model-related operations and information </span>
<span class="sd">    exchange.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        All these parameters should be passed in a dictionary that contains the following keys.</span>
<span class="sd">    model-name : str </span>
<span class="sd">        Indicates the model to be used</span>
<span class="sd">    device : str</span>
<span class="sd">        Name of the device used</span>
<span class="sd">    learning-rate : float </span>
<span class="sd">        Learning rate</span>
<span class="sd">    weight-decay : float </span>
<span class="sd">        Regularization used</span>
<span class="sd">    milestones : list </span>
<span class="sd">        List of the milestones, where the learning rate decay should be applied</span>
<span class="sd">    learning-rate-decay : float </span>
<span class="sd">        Rate decreases over time during training</span>

<span class="sd">    Methods</span>
<span class="sd">    --------</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
            <span class="n">lr</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> 
            <span class="n">weight_decay</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">milestones</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">],</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">]</span>
        <span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">get_flat_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Get the gradients of the model in a flat array</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        List of the gradients</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">get_flat_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Get the gradients of the model in a flat array</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        List of the gradients</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_dict_gradients</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">get_dict_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        ------------</span>
<span class="sd">        Get the gradients of the model in a dictionary.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dicctionary where the keys are the name of the parameters</span>
<span class="sd">        and de values are the gradients.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_dict_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        ------------</span>
<span class="sd">        Get the gradients of the model in a dictionary.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dicctionary where the keys are the name of the parameters</span>
<span class="sd">        and the values are the gradients.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">grad</span>
        <span class="k">return</span> <span class="n">new_dict</span>
    
    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_vector</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Sets the model parameters given a flat vector.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        flat_vector : list </span>
<span class="sd">            Flat list with the parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="n">unflatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">flat_vector</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">new_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_vector</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Sets the model gradients given a flat vector.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        flat_vector : list</span>
<span class="sd">            Flat list with the parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="n">unflatten_generator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">flat_vector</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">value</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">set_model_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Sets the state_dict of the model for the state_dict given by parameter.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        state_dict : dict </span>
<span class="sd">            State_dict from a model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

    
<div class="viewcode-block" id="Client">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client">[docs]</a>
<span class="k">class</span> <span class="nc">Client</span><span class="p">(</span><span class="n">ModelBaseInterface</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>
<span class="sd">    The ``Client`` class simulates a single honest node capable of training its local model, </span>
<span class="sd">    sending gradients, and receiving the global model in every training round.</span>

<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - **Local Training**: Performs training on a local dataset using a specified model and optimizer.</span>
<span class="sd">    - **Gradient Computation**: Computes gradients for the local dataset.</span>
<span class="sd">    - **Momentum Support**: Supports momentum for gradient updates.</span>
<span class="sd">    - **Label Flipping Attack**: Optionally applies a label flipping attack during training.</span>

<span class="sd">    Initialization Parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    params : dict</span>
<span class="sd">        A dictionary containing the configuration for the Client. Must include:</span>

<span class="sd">        - `&quot;model_name&quot;`: str</span>
<span class="sd">            Name of the model to be used. For a complete list of available models within the framework, refer to :ref:`models-label`.</span>
<span class="sd">        - `&quot;device&quot;`: str</span>
<span class="sd">            Device for computation (e.g., &#39;cpu&#39; or &#39;cuda&#39;).</span>
<span class="sd">        - `&quot;learning_rate&quot;`: float</span>
<span class="sd">            Learning rate for the optimizer.</span>
<span class="sd">        - `&quot;loss_name&quot;`: str</span>
<span class="sd">            Loss function name (e.g., &#39;CrossEntropyLoss&#39;).</span>
<span class="sd">        - `&quot;weight_decay&quot;`: float</span>
<span class="sd">            Weight decay for regularization.</span>
<span class="sd">        - `&quot;milestones&quot;`: list</span>
<span class="sd">            Milestones for learning rate decay.</span>
<span class="sd">        - `&quot;learning_rate_decay&quot;`: float</span>
<span class="sd">            Learning rate decay factor.</span>
<span class="sd">        - `&quot;LabelFlipping&quot;`: bool</span>
<span class="sd">            A boolean flag that, when set to True, enables the LabelFlipping attack. This attack flips the class labels of the training data to their opposing classes.</span>
<span class="sd">        - `&quot;momentum&quot;`: float</span>
<span class="sd">            Momentum for the optimizer.</span>
<span class="sd">        - `&quot;training_dataloader&quot;`: DataLoader</span>
<span class="sd">            DataLoader for the training data.</span>
<span class="sd">        - `&quot;nb_labels&quot;`: int</span>
<span class="sd">            Number of labels in the dataset.</span>
<span class="sd">        - `&quot;nb_steps&quot;`: int</span>
<span class="sd">            Number of training steps.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    compute_gradients</span>
<span class="sd">        Computes gradients for the local dataset.</span>
<span class="sd">    get_flat_flipped_gradients</span>
<span class="sd">        Returns the gradients of the model with flipped targets in a flat array.</span>
<span class="sd">    get_flat_gradients_with_momentum</span>
<span class="sd">        Returns flattened gradients with momentum applied.</span>
<span class="sd">    get_loss_list</span>
<span class="sd">        Returns the list of training losses.</span>
<span class="sd">    get_train_accuracy</span>
<span class="sd">        Returns the training accuracy per batch.</span>
<span class="sd">    set_model_state(state_dict)</span>
<span class="sd">        Updates the model&#39;s state dictionary.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Initialize the `Client` class with an MNIST data loader:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from torch.utils.data import DataLoader</span>
<span class="sd">    &gt;&gt;&gt; from torchvision import datasets, transforms</span>
<span class="sd">    &gt;&gt;&gt; from byzfl import Client</span>

<span class="sd">    &gt;&gt;&gt; # Fix the random seed of torch</span>
<span class="sd">    &gt;&gt;&gt; SEED = 42</span>
<span class="sd">    &gt;&gt;&gt; torch.manual_seed(SEED)</span>
<span class="sd">    &gt;&gt;&gt; torch.cuda.manual_seed(SEED)</span>
<span class="sd">    &gt;&gt;&gt; torch.backends.cudnn.deterministic = True</span>
<span class="sd">    &gt;&gt;&gt; torch.backends.cudnn.benchmark = False</span>
<span class="sd">    &gt;&gt;&gt; # Define the training data loader using MNIST</span>
<span class="sd">    &gt;&gt;&gt; transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])</span>
<span class="sd">    &gt;&gt;&gt; train_dataset = datasets.MNIST(root=&quot;./data&quot;, train=True, download=True, transform=transform)</span>
<span class="sd">    &gt;&gt;&gt; train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)</span>

<span class="sd">    &gt;&gt;&gt; # Define client parameters</span>
<span class="sd">    &gt;&gt;&gt; client_params = {</span>
<span class="sd">    &gt;&gt;&gt;     &quot;model_name&quot;: &quot;cnn_mnist&quot;, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;device&quot;: &quot;cpu&quot;, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;learning_rate&quot;: 0.01, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;loss_name&quot;: &quot;CrossEntropyLoss&quot;, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;weight_decay&quot;: 0.0005, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;milestones&quot;: [10, 20], </span>
<span class="sd">    &gt;&gt;&gt;     &quot;learning_rate_decay&quot;: 0.5, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;LabelFlipping&quot;: True, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;momentum&quot;: 0.9, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;training_dataloader&quot;: train_loader, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;nb_labels&quot;: 10, </span>
<span class="sd">    &gt;&gt;&gt;     &quot;nb_steps&quot;: len(train_loader)</span>
<span class="sd">    &gt;&gt;&gt; }</span>

<span class="sd">    &gt;&gt;&gt; # Initialize the Client</span>
<span class="sd">    &gt;&gt;&gt; client = Client(client_params)</span>

<span class="sd">    Compute gradients for the current training batch:</span>

<span class="sd">    &gt;&gt;&gt; # Compute first gradient</span>
<span class="sd">    &gt;&gt;&gt; client.compute_gradients()</span>
<span class="sd">    &gt;&gt;&gt; # Initial train accuracy</span>
<span class="sd">    &gt;&gt;&gt; client.get_train_accuracy()[0]</span>
<span class="sd">    &gt;&gt;&gt; # Get first flipped gradient</span>
<span class="sd">    &gt;&gt;&gt; client.get_flat_flipped_gradients()</span>
<span class="sd">    tensor([-0.0005,  0.0008,  0.0027,  ...,  0.0732,  0.0722, -0.0281])</span>
<span class="sd">    0.171875</span>
<span class="sd">    tensor([-0.0002, -0.0027, -0.0032,  ..., -0.0675, -0.0215, -0.0125])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>

        <span class="c1"># Check for correct types and values in params</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">],</span> <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">],</span> <span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">],</span> <span class="s2">&quot;milestones&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">miletsone</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">]:</span>
            <span class="n">check_type</span><span class="p">(</span><span class="n">miletsone</span><span class="p">,</span> <span class="s2">&quot;miletsone&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;loss_name&quot;</span><span class="p">],</span> <span class="s2">&quot;loss_name&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;LabelFlipping&quot;</span><span class="p">],</span> <span class="s2">&quot;LabelFlipping&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_labels&quot;</span><span class="p">],</span> <span class="s2">&quot;nb_labels&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_labels&quot;</span><span class="p">],</span> <span class="s2">&quot;nb_labels&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">],</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_or_equal_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">],</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_smaller_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">],</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;training_dataloader&quot;</span><span class="p">],</span> <span class="s2">&quot;training_dataloader&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_steps&quot;</span><span class="p">],</span> <span class="s2">&quot;nb_steps&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_steps&quot;</span><span class="p">],</span> <span class="s2">&quot;nb_steps&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Initialize Client instance</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">({</span>
            <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">],</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">],</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span>
            <span class="s2">&quot;milestones&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">],</span>
            <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span>
        <span class="p">})</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;loss_name&quot;</span><span class="p">])()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_LF</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labelflipping</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;LabelFlipping&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_labels</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_labels&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum_gradient</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span>
                <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> 
                <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
            <span class="p">)),</span>
            <span class="n">device</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;training_dataloader&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_steps&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_acc_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;nb_steps&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SGD_step</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_sample_train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private function to get the next data from the dataloader.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_iterator</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_iterator</span><span class="p">)</span>

<div class="viewcode-block" id="Client.compute_gradients">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.compute_gradients">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradients of the local model loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_train_batch</span><span class="p">()</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">labelflipping</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">targets_flipped</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_labels</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets_flipped</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gradient_LF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dict_gradients</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">SGD_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Compute train accuracy</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_acc_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">SGD_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">SGD_step</span> <span class="o">+=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="Client.get_flat_flipped_gradients">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.get_flat_flipped_gradients">[docs]</a>
    <span class="k">def</span> <span class="nf">get_flat_flipped_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the gradients of the model with flipped targets in a flat array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_LF</span><span class="p">)</span></div>


<div class="viewcode-block" id="Client.get_flat_gradients_with_momentum">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.get_flat_gradients_with_momentum">[docs]</a>
    <span class="k">def</span> <span class="nf">get_flat_gradients_with_momentum</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the gradients with momentum applied in a flat array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum_gradient</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum_gradient</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_flat_gradients</span><span class="p">(),</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum_gradient</span></div>


<div class="viewcode-block" id="Client.get_loss_list">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.get_loss_list">[docs]</a>
    <span class="k">def</span> <span class="nf">get_loss_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the list of computed losses over training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_list</span></div>


<div class="viewcode-block" id="Client.get_train_accuracy">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.get_train_accuracy">[docs]</a>
    <span class="k">def</span> <span class="nf">get_train_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the training accuracy per batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_acc_list</span></div>


<div class="viewcode-block" id="Client.set_model_state">
<a class="viewcode-back" href="../../../fed_framework/classes/client.html#byzfl.Client.set_model_state">[docs]</a>
    <span class="k">def</span> <span class="nf">set_model_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates the model state with the provided state dictionary.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        state_dict : dict</span>
<span class="sd">            The state dictionary of a model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="RobustAggregator">
<a class="viewcode-back" href="../../../fed_framework/classes/robust_aggregators.html#byzfl.RobustAggregator">[docs]</a>
<span class="k">class</span> <span class="nc">RobustAggregator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>
<span class="sd">    The ``RobustAggregator`` class is a comprehensive utility for applying pre-aggregations and aggregations to a set of input vectors.</span>
<span class="sd">    This class combines multiple pre-aggregation steps with a robust aggregation method, ensuring that the input data is processed efficiently and reliably to mitigate the effects of adversarial inputs or outliers.</span>

<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - **Pre-Aggregation**: Enables the application of multiple pre-aggregation steps in a sequential manner, </span>
<span class="sd">      such as :ref:`clipping-label` or :ref:`nnm-label`, to refine input vectors before aggregation.</span>
<span class="sd">    - **Robust Aggregation**: Integrates robust aggregation methods like :ref:`trmean-label` (TrMean) to compute </span>
<span class="sd">      an output vector resilient to Byzantine inputs.</span>
<span class="sd">    - **Compatibility**: Works seamlessly with NumPy arrays, PyTorch tensors, and lists of these data types.</span>

<span class="sd">    Initialization Parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    aggregator_info : dict </span>
<span class="sd">        A dictionary specifying the aggregation method and its parameters.</span>

<span class="sd">        - **Keys**:</span>
<span class="sd">            - `&quot;name&quot;`: str</span>
<span class="sd">                Name of the aggregation method (e.g., `&quot;TrMean&quot;`).</span>
<span class="sd">            - `&quot;parameters&quot;`: dict</span>
<span class="sd">                A dictionary of parameters required by the specified aggregation method.</span>
<span class="sd">    pre_agg_list : list, optional (default: [])</span>
<span class="sd">        A list of dictionaries, each specifying a pre-aggregation method and its parameters.</span>

<span class="sd">        - **Keys**:</span>
<span class="sd">            - `&quot;name&quot;`: str</span>
<span class="sd">                Name of the pre-aggregation method (e.g., `&quot;NNM&quot;`).</span>
<span class="sd">            - `&quot;parameters&quot;`: dict</span>
<span class="sd">                A dictionary of parameters required by the specified pre-aggregation method.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    aggregate_vectors(vectors)</span>
<span class="sd">        Applies the specified pre-aggregation and aggregation methods to the input vectors, returning the aggregated result.</span>

<span class="sd">    Calling the Instance</span>
<span class="sd">    --------------------</span>
<span class="sd">    Input Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors : numpy.ndarray, torch.Tensor, list of numpy.ndarray, or list of torch.Tensor</span>
<span class="sd">        A collection of input vectors, matrices, or tensors to process.</span>
<span class="sd">        These vectors conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray or torch.Tensor</span>
<span class="sd">        The aggregated output vector with the same data type as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Initialize the `RobustAggregator` with both pre-aggregation and aggregation methods:</span>

<span class="sd">    &gt;&gt;&gt; from byzfl import RobustAggregator</span>
<span class="sd">    &gt;&gt;&gt; # Define pre-aggregation methods</span>
<span class="sd">    &gt;&gt;&gt; pre_aggregators = [</span>
<span class="sd">    &gt;&gt;&gt;     {&quot;name&quot;: &quot;Clipping&quot;, &quot;parameters&quot;: {&quot;c&quot;: 2.0}},</span>
<span class="sd">    &gt;&gt;&gt;     {&quot;name&quot;: &quot;NNM&quot;, &quot;parameters&quot;: {&quot;f&quot;: 1}},</span>
<span class="sd">    &gt;&gt;&gt; ]</span>
<span class="sd">    &gt;&gt;&gt; # Define an aggregation method</span>
<span class="sd">    &gt;&gt;&gt; aggregator_info = {&quot;name&quot;: &quot;TrMean&quot;, &quot;parameters&quot;: {&quot;f&quot;: 1}}</span>
<span class="sd">    &gt;&gt;&gt; # Create the RobustAggregator instance</span>
<span class="sd">    &gt;&gt;&gt; rob_agg = RobustAggregator(aggregator_info, pre_agg_list=pre_aggregators)</span>

<span class="sd">    Apply the RobustAggregator to various types of input data:</span>

<span class="sd">    Using NumPy arrays:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; vectors = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; rob_agg.aggregate_vectors(vectors)</span>
<span class="sd">    array([0.95841302, 1.14416941, 1.3299258])</span>

<span class="sd">    Using PyTorch tensors:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; vectors = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; rob_agg.aggregate_vectors(vectors)</span>
<span class="sd">    tensor([0.9584, 1.1442, 1.3299])</span>

<span class="sd">    Using a list of NumPy arrays:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; vectors = [np.array([1., 2., 3.]), np.array([4., 5., 6.]), np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; rob_agg.aggregate_vectors(vectors)</span>
<span class="sd">    array([0.95841302, 1.14416941, 1.3299258])</span>

<span class="sd">    Using a list of PyTorch tensors:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; vectors = [torch.tensor([1., 2., 3.]), torch.tensor([4., 5., 6.]), torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; rob_agg.aggregate_vectors(vectors)</span>
<span class="sd">    tensor([0.9584, 1.1442, 1.3299])</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Pre-aggregations are applied in the order they are listed in `pre_agg_list`.</span>
<span class="sd">    - The class dynamically initializes pre-aggregation and aggregation methods based on the provided configurations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggregator_info</span><span class="p">,</span> <span class="n">pre_agg_list</span><span class="o">=</span><span class="p">[]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the RobustAggregator with the specified pre-aggregation and aggregation configurations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        aggregator_info : dict</span>
<span class="sd">            Dictionary specifying the aggregation method and its parameters.</span>
<span class="sd">        pre_agg_list : list, optional</span>
<span class="sd">            List of dictionaries specifying pre-aggregation methods and their parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check for correct types and values in params</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">aggregator_info</span><span class="p">,</span> <span class="s2">&quot;aggregator_info&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">pre_agg_list</span><span class="p">,</span> <span class="s2">&quot;pre_agg_list&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pre_agg</span> <span class="ow">in</span> <span class="n">pre_agg_list</span><span class="p">:</span>
            <span class="n">check_type</span><span class="p">(</span><span class="n">pre_agg</span><span class="p">,</span> <span class="s2">&quot;pre_agg&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>

        <span class="c1"># Initialize the RobustAggregator instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">aggregators</span><span class="p">,</span> <span class="n">aggregator_info</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
        <span class="n">signature_agg</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
        <span class="n">agg_parameters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">aggregator_info</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">default</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">signature_agg</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">aggregator_info</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span><span class="p">(</span><span class="o">**</span><span class="n">agg_parameters</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pre_agg_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pre_agg_info</span> <span class="ow">in</span> <span class="n">pre_agg_list</span><span class="p">:</span>
            <span class="n">pre_agg</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">preaggregators</span><span class="p">,</span> <span class="n">pre_agg_info</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
            <span class="n">signature_pre_agg</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">pre_agg</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
            <span class="n">pre_agg_parameters</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">pre_agg_info</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">default</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">signature_pre_agg</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">pre_agg_info</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_agg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pre_agg</span><span class="p">(</span><span class="o">**</span><span class="n">pre_agg_parameters</span><span class="p">))</span>

<div class="viewcode-block" id="RobustAggregator.aggregate_vectors">
<a class="viewcode-back" href="../../../fed_framework/classes/robust_aggregators.html#byzfl.RobustAggregator.aggregate_vectors">[docs]</a>
    <span class="k">def</span> <span class="nf">aggregate_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the configured pre-aggregations and robust aggregation method to the input vectors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        vectors : numpy.ndarray, torch.Tensor, list of numpy.ndarray, or list of torch.Tensor</span>
<span class="sd">            A collection of input vectors to process.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray or torch.Tensor</span>
<span class="sd">            The aggregated output vector with the same data type as the input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">pre_agg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_agg_list</span><span class="p">:</span>
            <span class="n">vectors</span> <span class="o">=</span> <span class="n">pre_agg</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="ByzantineClient">
<a class="viewcode-back" href="../../../fed_framework/classes/byzantine_client.html#byzfl.ByzantineClient">[docs]</a>
<span class="k">class</span> <span class="nc">ByzantineClient</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>
<span class="sd">    The ``ByzantineClient`` class is responsible for simulating Byzantine behavior in distributed machine learning </span>
<span class="sd">    by executing a specified Byzantine attack. It applies an attack to the gradients (or input vectors) </span>
<span class="sd">    submitted by honest participants and generates multiple faulty (Byzantine) vectors.</span>

<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - Supports various Byzantine attack strategies through dynamic initialization.</span>
<span class="sd">    - Allows customization of attack parameters and the number of faulty nodes.</span>
<span class="sd">    - Compatible with both NumPy and PyTorch tensors, as well as lists of these data types.</span>

<span class="sd">    Initialization Parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    params : dict</span>
<span class="sd">        A dictionary containing the configuration for the Byzantine attack. Must include:</span>

<span class="sd">        - `&quot;f&quot;`: int</span>
<span class="sd">            The number of faulty (Byzantine) vectors to generate.</span>
<span class="sd">        - `&quot;name&quot;`: str</span>
<span class="sd">            The name of the attack to be executed (e.g., `&quot;InnerProductManipulation&quot;`).</span>
<span class="sd">        - `&quot;parameters&quot;`: dict</span>
<span class="sd">            A dictionary of parameters for the specified attack, where keys are parameter names and values are their corresponding values.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    apply_attack(honest_vectors)</span>
<span class="sd">        Applies the specified Byzantine attack to the input vectors and returns a list of faulty vectors.</span>

<span class="sd">    Calling the Instance</span>
<span class="sd">    --------------------</span>
<span class="sd">    Input Parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    honest_vectors : numpy.ndarray, torch.Tensor, list of numpy.ndarray, or list of torch.Tensor</span>
<span class="sd">        A collection of input vectors, matrices, or tensors representing gradients submitted by honest participants.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        A list containing `f` faulty vectors generated by the Byzantine attack, each with the same data type as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Initialize the `ByzantineClient` with a specific attack and apply it to input vectors:</span>

<span class="sd">    &gt;&gt;&gt; from byzfl import ByzantineClient</span>
<span class="sd">    &gt;&gt;&gt; attack = {</span>
<span class="sd">    &gt;&gt;&gt;     &quot;name&quot;: &quot;InnerProductManipulation&quot;,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;f&quot;: 3,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;parameters&quot;: {&quot;tau&quot;: 3.0},</span>
<span class="sd">    &gt;&gt;&gt; }</span>
<span class="sd">    &gt;&gt;&gt; byz_worker = ByzantineClient(attack)</span>

<span class="sd">    Using numpy arrays:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; honest_vectors = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; byz_worker.apply_attack(honest_vectors)</span>
<span class="sd">    [array([-12., -15., -18.]), array([-12., -15., -18.]), array([-12., -15., -18.])]</span>

<span class="sd">    Using torch tensors:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; honest_vectors = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; byz_worker.apply_attack(honest_vectors)</span>
<span class="sd">    [tensor([-12., -15., -18.]), tensor([-12., -15., -18.]), tensor([-12., -15., -18.])]</span>

<span class="sd">    Using a list of numpy arrays:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; honest_vectors = [np.array([1., 2., 3.]), np.array([4., 5., 6.]), np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; byz_worker.apply_attack(honest_vectors)</span>
<span class="sd">    [array([-12., -15., -18.]), array([-12., -15., -18.]), array([-12., -15., -18.])]</span>

<span class="sd">    Using a list of torch tensors:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; honest_vectors = [torch.tensor([1., 2., 3.]), torch.tensor([4., 5., 6.]), torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; byz_worker.apply_attack(honest_vectors)</span>
<span class="sd">    [tensor([-12., -15., -18.]), tensor([-12., -15., -18.]), tensor([-12., -15., -18.])]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the ByzantineClient with the specified attack configuration.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary with the attack configuration. Must include:</span>
<span class="sd">            - `&quot;f&quot;`: int</span>
<span class="sd">                Number of faulty vectors.</span>
<span class="sd">            - `&quot;name&quot;`: str</span>
<span class="sd">                Name of the attack to execute.</span>
<span class="sd">            - `&quot;parameters&quot;`: dict</span>
<span class="sd">                Parameters for the specified attack.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check for correct types and values in params</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;f&quot;</span><span class="p">],</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="n">check_greater_than_or_equal_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;f&quot;</span><span class="p">],</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">],</span> <span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">],</span> <span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>

        <span class="c1"># Initialize the ByzantineClient instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;f&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attack</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="n">attacks</span><span class="p">,</span> 
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
        <span class="p">)(</span><span class="o">**</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">])</span>

<div class="viewcode-block" id="ByzantineClient.apply_attack">
<a class="viewcode-back" href="../../../fed_framework/classes/byzantine_client.html#byzfl.ByzantineClient.apply_attack">[docs]</a>
    <span class="k">def</span> <span class="nf">apply_attack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">honest_vectors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the specified Byzantine attack to the input vectors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        honest_vectors : numpy.ndarray, torch.Tensor, list of numpy.ndarray, or list of torch.Tensor</span>
<span class="sd">            A collection of input vectors, matrices, or tensors representing gradients submitted by honest participants.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            A list containing `f` faulty (Byzantine) vectors generated by the attack, each with the same data type as the input.</span>
<span class="sd">            If `f = 0`, an empty list is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">check_smaller_than_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">honest_vectors</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Generate the Byzantine vector by applying the attack</span>
        <span class="n">byz_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attack</span><span class="p">(</span><span class="n">honest_vectors</span><span class="p">)</span>

        <span class="c1"># Return a list of the same Byzantine vector repeated `f` times</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">byz_vector</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span></div>
</div>



<div class="viewcode-block" id="Server">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server">[docs]</a>
<span class="k">class</span> <span class="nc">Server</span><span class="p">(</span><span class="n">ModelBaseInterface</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>
<span class="sd">    The ``Server`` class simulates the central server in a federated learning setup, responsible for aggregating gradients, updating the global model, and evaluating its performance. This class seamlessly integrates robust aggregation methods to mitigate the impact of Byzantine participants and ensures efficient global model updates.</span>

<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - **Gradient Aggregation**: Supports robust aggregation of client gradients using pre-aggregators and aggregators like :ref:`trmean-label`.</span>
<span class="sd">    - **Model Updates**: Aggregates gradients from clients and updates the global model accordingly.</span>
<span class="sd">    - **Performance Evaluation**: Computes accuracy on validation and test datasets.</span>
<span class="sd">    - **Integration**: Works in conjunction with `Client` and `ByzantineClient` classes to simulate realistic federated learning scenarios.</span>

<span class="sd">    Initialization Parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    params : dict</span>
<span class="sd">        A dictionary containing the configuration for the Server. Must include:</span>

<span class="sd">        - `&quot;model_name&quot;`: str</span>
<span class="sd">            Name of the model to be used. Refer to :ref:`models-label` for available models.</span>
<span class="sd">        - `&quot;device&quot;`: str</span>
<span class="sd">            Name of the device to be used for computations (e.g., `&quot;cpu&quot;`, `&quot;cuda&quot;`).</span>
<span class="sd">        - `&quot;learning_rate&quot;`: float</span>
<span class="sd">            Learning rate for the global model optimizer.</span>
<span class="sd">        - `&quot;weight_decay&quot;`: float</span>
<span class="sd">            Weight decay (L2 regularization) for the optimizer.</span>
<span class="sd">        - `&quot;milestones&quot;`: list</span>
<span class="sd">            List of epochs at which the learning rate decay is applied.</span>
<span class="sd">        - `&quot;learning_rate_decay&quot;`: float</span>
<span class="sd">            Factor by which the learning rate is reduced at each milestone.</span>
<span class="sd">        - `&quot;aggregator_info&quot;`: dict</span>
<span class="sd">            Dictionary specifying the aggregation method and its parameters:</span>
<span class="sd">            - `&quot;name&quot;`: str, name of the aggregator (e.g., `&quot;TrMean&quot;`).</span>
<span class="sd">            - `&quot;parameters&quot;`: dict, parameters for the aggregator.</span>
<span class="sd">        - `&quot;pre_agg_list&quot;`: list</span>
<span class="sd">            List of dictionaries specifying pre-aggregation methods and their parameters:</span>
<span class="sd">            - `&quot;name&quot;`: str, name of the pre-aggregator (e.g., `&quot;Clipping&quot;`).</span>
<span class="sd">            - `&quot;parameters&quot;`: dict, parameters for the pre-aggregator.</span>
<span class="sd">        - `&quot;test_loader&quot;`: DataLoader</span>
<span class="sd">            DataLoader for the test dataset to evaluate the global model.</span>
<span class="sd">        - `&quot;validation_loader&quot;`: DataLoader (optional)</span>
<span class="sd">            DataLoader for the validation dataset to monitor training performance.</span>
<span class="sd">    </span>
<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    aggregate(vectors)</span>
<span class="sd">        Aggregates input vectors using the configured robust aggregator.</span>
<span class="sd">    update_model(gradients)</span>
<span class="sd">        Updates the global model using aggregated gradients.</span>
<span class="sd">    step()</span>
<span class="sd">        Executes a single optimization step for the global model.</span>
<span class="sd">    get_model()</span>
<span class="sd">        Returns the current global model.</span>
<span class="sd">    compute_validation_accuracy()</span>
<span class="sd">        Computes accuracy on the validation dataset.</span>
<span class="sd">    compute_test_accuracy()</span>
<span class="sd">        Computes accuracy on the test dataset.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    Initialize MNIST test data loader:</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from torch.utils.data import DataLoader</span>
<span class="sd">    &gt;&gt;&gt; from torchvision import datasets, transforms</span>
<span class="sd">    &gt;&gt;&gt; from byzfl import Client, Server, ByzantineClient</span>
<span class="sd">    &gt;&gt;&gt; # Define data loader using MNIST</span>
<span class="sd">    &gt;&gt;&gt; transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])</span>
<span class="sd">    &gt;&gt;&gt; test_dataset = datasets.MNIST(root=&quot;./data&quot;, train=False, download=True, transform=transform)</span>
<span class="sd">    &gt;&gt;&gt; test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)</span>

<span class="sd">    Initialize the Server class:</span>

<span class="sd">    &gt;&gt;&gt; # Define pre-aggregators and aggregator</span>
<span class="sd">    &gt;&gt;&gt; pre_aggregators = [{&quot;name&quot;: &quot;Clipping&quot;, &quot;parameters&quot;: {&quot;c&quot;: 2.0}}, {&quot;name&quot;: &quot;NNM&quot;, &quot;parameters&quot;: {&quot;f&quot;: 1}}]</span>
<span class="sd">    &gt;&gt;&gt; aggregator_info = {&quot;name&quot;: &quot;TrMean&quot;, &quot;parameters&quot;: {&quot;f&quot;: 1}}</span>
<span class="sd">    &gt;&gt;&gt; # Define server parameters</span>
<span class="sd">    &gt;&gt;&gt; server_params = {</span>
<span class="sd">    &gt;&gt;&gt;     &quot;device&quot;: &quot;cpu&quot;,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;model_name&quot;: &quot;cnn_mnist&quot;,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;test_loader&quot;: test_loader,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;learning_rate&quot;: 0.01,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;weight_decay&quot;: 0.0005,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;milestones&quot;: [10, 20],</span>
<span class="sd">    &gt;&gt;&gt;     &quot;learning_rate_decay&quot;: 0.5,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;aggregator_info&quot;: aggregator_info,</span>
<span class="sd">    &gt;&gt;&gt;     &quot;pre_agg_list&quot;: pre_aggregators,</span>
<span class="sd">    &gt;&gt;&gt; }</span>
<span class="sd">    &gt;&gt;&gt; # Initialize the Server</span>
<span class="sd">    &gt;&gt;&gt; server = Server(server_params)</span>

<span class="sd">    Aggregation and model update:</span>

<span class="sd">    &gt;&gt;&gt; # Perform aggregation and model updates</span>
<span class="sd">    &gt;&gt;&gt; gradients = [...]  # Collect gradients from clients</span>
<span class="sd">    &gt;&gt;&gt; server.update_model(gradients)</span>
<span class="sd">    &gt;&gt;&gt; print(&quot;Test Accuracy:&quot;, server.compute_test_accuracy())</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>

        <span class="c1"># Check for correct types and values in params</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">],</span> <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">],</span> <span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">],</span> <span class="s2">&quot;milestones&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">miletsone</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">]:</span>
            <span class="n">check_type</span><span class="p">(</span><span class="n">miletsone</span><span class="p">,</span> <span class="s2">&quot;miletsone&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_greater_than_value</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span> <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">check_type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;test_loader&quot;</span><span class="p">],</span> <span class="s2">&quot;test_loader&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">)</span>

        <span class="c1"># Initialize the Server instance</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">({</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">],</span>
            <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">],</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span>
            <span class="s2">&quot;milestones&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;milestones&quot;</span><span class="p">],</span>
            <span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate_decay&quot;</span><span class="p">],</span>
        <span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">robust_aggregator</span> <span class="o">=</span> <span class="n">RobustAggregator</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;aggregator_info&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;pre_agg_list&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;test_loader&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="s2">&quot;validation_loader&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;validation_loader&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span><span class="p">,</span> <span class="s2">&quot;validation_loader&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<div class="viewcode-block" id="Server.aggregate">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.aggregate">[docs]</a>
    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Aggregates input vectors using the configured robust aggregator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        vectors : list or np.ndarray or torch.Tensor</span>
<span class="sd">            A collection of input vectors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Aggregated output vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">robust_aggregator</span><span class="o">.</span><span class="n">aggregate_vectors</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span></div>


<div class="viewcode-block" id="Server.update_model">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.update_model">[docs]</a>
    <span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Updates the global model by aggregating gradients and performing an optimization step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gradients : list</span>
<span class="sd">            List of gradients to aggregate and apply.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">aggregate_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_gradients</span><span class="p">(</span><span class="n">aggregate_gradient</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">()</span></div>


<div class="viewcode-block" id="Server.step">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.step">[docs]</a>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Performs a single optimization step for the global model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span></div>


<div class="viewcode-block" id="Server.get_model">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.get_model">[docs]</a>
    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Retrieves the current global model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Module</span>
<span class="sd">            The current global model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>


    <span class="k">def</span> <span class="nf">_compute_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

<div class="viewcode-block" id="Server.compute_validation_accuracy">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.compute_validation_accuracy">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_validation_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Computes the accuracy of the global model on the validation dataset.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Validation accuracy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Data Loader is not set.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span><span class="p">)</span></div>


<div class="viewcode-block" id="Server.compute_test_accuracy">
<a class="viewcode-back" href="../../../fed_framework/classes/server.html#byzfl.Server.compute_test_accuracy">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_test_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Computes the accuracy of the global model on the test dataset.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Test accuracy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">)</span></div>
</div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2024, EPFL.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.0.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>